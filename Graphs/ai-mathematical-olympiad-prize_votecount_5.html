<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 1920px;
                 height: 1080px;
                 background-color: #222222;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"font": {"color": "white"}, "group": 2, "id": "torch", "label": "torch", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "label": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "shape": "dot", "size": 10, "title": "Unique aspects:\n1. The use of the BitsAndBytesConfig to enable quantization and mixed-precision training for the Mixtral8x7b model.\n2. The integration of gradient checkpointing to prevent GPU memory overflow.\n\nSteps taken:\n1. Install the necessary packages, including PyTorch and transformers.\n2. Load the pre-trained Mixtral8x7b model and tokenizer.\n3. Define a custom pipeline for text generation using the transformers library.\n4. Process the output of the pipeline to extract code blocks and execute them to obtain results.\n5. Integrate natural language reasoning with programs to solve mathematical problems.\n\nSummary:\nThis code uses the BitsAndBytesConfig to enable quantization and mixed-precision training for the Mixtral8x7b model, allowing for more efficient training. It also employs gradient checkpointing to prevent GPU memory overflow. The code then generates prompts using a template-based approach and uses the Mixtral8x7b model to generate responses. The responses are parsed to extract numerical answers, which are then used to evaluate the performance of the model."}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "label": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "shape": "dot", "size": 13, "title": "Here is a summary of the unique aspects of this Machine Learning code written in Python:\n\n**Key Features:**\n\n1. **Generative Model**: The code uses a generative model to generate text output based on input prompts.\n2. **Tokenization and Decoding**: It utilizes tokenization and decoding techniques to process the generated text output.\n3. **Stop Words and Conditionals**: The code includes stop words and conditionals to filter out unwanted outputs and ensure the model produces relevant results.\n\n**Unique Aspects:**\n\n1. **Context-Aware Generation**: The model generates text based on input prompts, taking into account context and semantics.\n2. **Code Output Evaluation**: It evaluates the generated code output using `eval()` and rounds the result to a specific value (in this case, 1000).\n3. **Answer Tracking and Statistics**: The code keeps track of the number of correct answers, best answer statistics, and question type counts.\n4. **Debugging and Visualization**: It includes debugging statements and visualizations to help diagnose issues and understand model performance.\n\n**Technical Details:**\n\n1. **Python Libraries:** The code uses Python libraries such as NumPy, Pandas, and Scikit-learn for data processing and manipulation.\n2. **Subprocess and Shell Commands:** It utilizes subprocesses and shell commands to execute external programs and scripts.\n3. **File Input/Output:** The code reads and writes CSV files using the Pandas library.\n\n**Potential Improvements:**\n\n1. **Model Fine-Tuning**: The model could be fine-tuned for better performance on specific tasks or datasets.\n2. **Error Handling**: Improved error handling mechanisms could be implemented to handle exceptions and edge cases more effectively.\n3. **Visualization and Interpretability**: Additional visualization tools and techniques could be used to provide insights into the model\u0027s behavior and decision-making process.\n\nOverall, this code demonstrates a robust approach to generative modeling, text processing, and answer tracking in Python."}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "label": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "shape": "dot", "size": 5, "title": "Here\u0027s a summary of the unique aspects of this Machine Learning code written in Python:\n\n1. **Pre-trained Model**: The code uses a pre-trained AutoModelForCausalLM model, which is loaded from a specified path using `AutoModelForCausalLM.from_pretrained()`. This allows for fine-tuning on specific tasks without requiring extensive training data.\n\n2. **Text Generation Pipeline**: A text generation pipeline is created using the `transformers` library, which enables natural language processing and generation capabilities. The pipeline is configured to generate text based on a given prompt and problem statement.\n\n3. **Naive Parsing**: A custom parsing function called `naive_parse()` is used to extract numerical answers from generated text. This involves reversing the input string and checking for numbers in specific positions.\n\n4. **Process Output**: Another custom function, `process_output()`, is used to process the output of the text generation pipeline. It attempts to execute the generated code, parse any boxed expressions (if present), and extract a numerical answer.\n\n5. **Repetitive Execution**: The code executes the text generation pipeline multiple times (5 or 2 times, depending on whether `PRIVATE` is True) with different prompts and problem statements. This allows for repeated attempts to generate accurate answers.\n\n6. **Counter-Based Answer Selection**: After processing the output of each execution, the code uses a `Counter` object to select the most common answer among the repetitions. If an answer is not available (i.e., -1), the code selects the next most common one.\n\n7. **Submission Generation**: The final answers are then used to generate a submission CSV file, which contains the problem IDs and corresponding answers.\n\n8. **Model Evaluation**: In non-private mode (`PRIVATE=False`), the code evaluates the performance of the model by comparing its predicted answers with actual solutions in the training dataset. It calculates the number of matches between the two sets of answers.\n\nThese unique aspects showcase the creative use of natural language processing, text generation, and repetitive execution to solve mathematical problems."}, {"font": {"color": "white"}, "group": 2, "id": "transformers", "label": "transformers", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 2, "id": "pandas", "label": "pandas", "shape": "dot", "size": 5}, {"font": {"color": "white"}, "group": 2, "id": "tqdm", "label": "tqdm", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "gc", "label": "gc", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 1, "id": "re", "label": "re", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 2, "id": "sys", "label": "sys", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "subprocess", "label": "subprocess", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "collections", "label": "collections", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 1, "id": "numpy", "label": "numpy", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "label": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "shape": "dot", "size": 39, "title": "A fascinating piece of Machine Learning code written in Python!\n\nAfter analyzing the code, I\u0027ve identified some unique aspects that are worth summarizing:\n\n**1. Inference Handler**: The `InferenceHandler` class is a crucial component of this code. It handles inference tasks by running a model on a given problem and returning the predicted answer.\n\n**2. Model Integration**: The code uses two models: `text_gen_pipeline` (VLLM) and `run_pipeline`. These models are integrated to generate predictions, which indicates that the authors are using a combination of natural language processing (NLP) and machine learning techniques.\n\n**3. Code Generation**: The code generates code by running the model on a problem prompt. This is achieved through the `infer` method, which takes in a problem text and returns the predicted answer.\n\n**4. Cross-Validation**: The authors implement cross-validation to evaluate their model\u0027s performance. They select a subset of 50 examples from the `ext_aimo_df` dataset for validation.\n\n**5. Code Processing**: The code processes the generated outputs by applying the `process_output` function. This function is used to clean and transform the output into a usable format.\n\n**6. Error Handling**: The code includes error handling mechanisms, such as trying to remove a file (`\"code_to_execute.py\"`). This suggests that the authors are aware of potential errors and have taken steps to handle them.\n\n**7. Data Preparation**: The code prepares data by selecting specific columns from the `ext_aimo_df` dataset and resetting the index. This indicates that the authors need to manipulate their data in some way before using it for inference or validation.\n\nThese unique aspects demonstrate the complexity of this Machine Learning code, which involves integrating multiple models, generating code, and processing outputs."}, {"font": {"color": "white"}, "group": 1, "id": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "label": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "shape": "dot", "size": 6, "title": "LoRA (Low-Rank Adaptation) is a method used to fine-tune large language models (LLMs) in an efficient way. It involves freezing the weights of the LLM and injecting trainable rank-decomposition matrices.\n\nTo use LoRA, you initialize two additional dense layers (A and B) with shapes d \u00d7 r and r \u00d7 d, respectively. The equation for the model\u0027s output becomes: `output = (W0 \u00b7 x + b0) + (B \u00b7 A \u00b7 x)`, where W0 is the original dense layer, A and B are the trainable rank-decomposition matrices.\n\nLoRA saves memory because the smaller layers (A and B) have fewer parameters to learn compared to the big model. This means that even though the overall model might seem bigger, it\u0027s actually more efficient in terms of parameter usage.\n\nUnique aspects of this Machine Learning code written in Python:\n\n* Fine-tuning a Gemma model using LoRA\n* Using Keras to implement LoRA\n* Experimenting with different prompt engineering techniques\n* Inference on AIMO dataset and preparing submission file\n* Utilizing the `tqdm` library for progress bars\n\nSome tips for improving performance:\n\n* Train on the full data instead of first 1000 samples.\n* Try using the non-instruction-tuned version of Gemma.\n* Increase the `sequence_length`.\n* Experiment with advanced prompt engineering techniques.\n* Implement augmentation to increase the number of samples.\n* Utilize a learning rate scheduler."}, {"font": {"color": "white"}, "group": 2, "id": "time", "label": "time", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 2, "id": "math", "label": "math", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 2, "id": "random", "label": "random", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "os", "label": "os", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "keras", "label": "keras", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "keras_nlp", "label": "keras_nlp", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "plotly", "label": "plotly", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "IPython", "label": "IPython", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "vllm", "label": "vllm", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "aimo", "label": "aimo", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "sympy", "label": "sympy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "typing", "label": "typing", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "kaggle_datasets", "label": "kaggle_datasets", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "dataclasses", "label": "dataclasses", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "datetime", "label": "datetime", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "zipfile", "label": "zipfile", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "glob", "label": "glob", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "warnings", "label": "warnings", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "requests", "label": "requests", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "textwrap", "label": "textwrap", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "hashlib", "label": "hashlib", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "imageio", "label": "imageio", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "urllib", "label": "urllib", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "pickle", "label": "pickle", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "shutil", "label": "shutil", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "string", "label": "string", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "json", "label": "json", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "copy", "label": "copy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "gzip", "label": "gzip", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "ast", "label": "ast", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "io", "label": "io", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "seaborn", "label": "seaborn", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "PIL", "label": "PIL", "shape": "dot", "size": 1}]);
                  edges = new vis.DataSet([{"from": "torch", "to": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "transformers", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "pandas", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "tqdm", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "gc", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "re", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "sys", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "subprocess", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "collections", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "numpy", "value": 5.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "time", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "math", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "random", "value": 2.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "os", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras_nlp", "value": 1.0, "width": 1}, {"from": "os", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "plotly", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "IPython", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "vllm", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "aimo", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "sympy", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "typing", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "kaggle_datasets", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "dataclasses", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "datetime", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "zipfile", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "glob", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "warnings", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "requests", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "textwrap", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "hashlib", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "imageio", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "urllib", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "pickle", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "shutil", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "string", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "json", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "copy", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "gzip", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "ast", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "io", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "seaborn", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "PIL", "value": 1.0, "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": "physics"
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>