<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 1920px;
                 height: 1080px;
                 background-color: #222222;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"font": {"color": "white"}, "group": 0, "id": "torch", "label": "torch", "shape": "dot", "size": 5}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "label": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "shape": "dot", "size": 10, "title": "**What exactly is LoRA?**\n\nLoRA (Low-Rank Adaptation) is a method used to fine-tune large language models (LLMs) in an efficient way. It involves freezing the weights of the LLM and injecting trainable rank-decomposition matrices.\n\nIn LoRA, we initialize two additional dense layers, labeled as A and B, with shapes d \u00d7 r and r \u00d7 d, respectively. Here, r denotes the rank, which is typically much smaller than d. The equation for computing the model\u0027s output changes from W0 \u00b7 x + b0 to (W0 \u00b7 x + b0) + (B \u00b7 A \u00b7 x), where A and B denote the trainable rank-decomposition matrices that have been introduced.\n\n**Why does LoRA save memory?**\n\nEven though we\u0027re adding more layers, LoRA saves memory because it uses a low-rank approximation of the original model\u0027s weights. This reduces the number of parameters to be updated during fine-tuning, making it more memory-efficient.\n\nIn this notebook, we use LoRA to fine-tune a Gemma model in Keras for the AIMO competition dataset. We also provide tips to enhance performance, such as training on the full data, trying non-instruction-tuned versions of Gemma, increasing sequence length, and experimenting with prompt engineering techniques."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "label": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "shape": "dot", "size": 13, "title": "Unique aspects:\n1. The use of the MMOS-DeepSeekMath model for zero-shot machine learning, which is pre-trained on a large dataset of mathematical problems.\n2. The integration of natural language processing (NLP) and computer programming to solve mathematical problems.\n\nSteps taken:\n1. Import necessary libraries and load the MMOS-DeepSeekMath model.\n2. Define a function to process the output of the NLP model and execute it as Python code.\n3. Use the NLP model to generate code for each problem in the dataset, and then execute that code to get the answer.\n4. Repeat the process multiple times (n_reps) for each problem to account for variability in the generated code.\n5. Combine the results from each repetition to get the final answer.\n\nNote: The provided code is quite long, so I only highlighted the main unique aspects and steps taken."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "label": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "shape": "dot", "size": 5, "title": "Unique aspects:\n\n1. The use of Mixtral8x7b, a pre-trained causal language model for prompt prediction.\n2. The integration of BitsAndBytesConfig to enable 4-bit quantization and double-quantized training.\n\nSteps taken:\n\n1. Import necessary libraries, including PyTorch, transformers, pandas, and tqdm.\n2. Load the pre-trained Mixtral8x7b model and tokenizer using AutoModelForCausalLM and AutoTokenizer.\n3. Define a custom pipeline for prompt prediction using the loaded model and tokenizer.\n4. Process the output of the pipeline to extract answers and convert them into numerical format.\n5. Integrate natural language processing with mathematical problem-solving to generate responses.\n\nSummary:\nThis code uses Mixtral8x7b, a pre-trained causal language model, to predict prompts and solve mathematical problems. It also employs BitsAndBytesConfig for 4-bit quantization and double-quantized training. The code integrates natural language processing with mathematical problem-solving to generate responses and evaluates the accuracy of its predictions."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "label": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "shape": "dot", "size": 6, "title": "Here\u0027s a summary of the unique aspects of this Machine Learning code written in Python:\n\n**Unique Features:**\n\n1. **Generation and Processing of Code Output**: The code uses a combination of generation and processing techniques to produce output, including decoding sequences from a tokenizer and applying a `process_text_output` function.\n2. **Conditional Execution**: The code includes conditional statements that execute different blocks of code based on the value of variables, such as `USE_PAST_KEY` and `DEBUG`.\n3. **Handling Exceptions**: The code uses try-except blocks to catch and handle exceptions, including a specific exception handler for evaluating code output.\n4. **Data Processing and Analysis**: The code performs data processing and analysis tasks, including counting the frequency of outputs and identifying the most common answers.\n5. **Private Mode**: The code includes a private mode that is triggered by setting a specific variable (`PRIVATE`). In this mode, the code performs additional data processing and analysis tasks.\n\n**Code Organization:**\n\nThe code is organized into several sections:\n\n1. **Initialization**: The code initializes variables and sets up data structures.\n2. **Main Loop**: The code loops through a dataset (represented by `df`) and executes the main logic of the code for each example.\n3. **Processing and Analysis**: The code performs processing and analysis tasks on the output, including counting frequencies and identifying most common answers.\n4. **Private Mode**: The code enters private mode if the `PRIVATE` variable is set.\n\n**Technical Details:**\n\n1. **Libraries Used**: The code uses the NumPy library (`numpy`) for numerical computations and the Pandas library (`pandas`) for data manipulation and analysis.\n2. **Subprocess Execution**: The code uses the `subprocess` module to execute a shell command and capture its output.\n\nOverall, this code demonstrates a combination of machine learning, natural language processing, and data analysis techniques, with a unique blend of generation, processing, and evaluation logic."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "label": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "shape": "dot", "size": 14, "title": "Unique aspects:\n1. The use of OpenMath models, specifically OpenMath-Mistral-7B-v0.1, which was trained on synthetic data created using PoT-like prompting for the Mixtral model.\n2. The reduction of parsing difficulties on the post-processing stage by designing training instructions to ensure the final answer is inside a \\boxed{} block.\n\nSteps taken:\n1. Imported necessary libraries, including pandas and transformers.\n2. Loaded OpenMath models and configured them for use with the pipeline.\n3. Defined a prompt template and user input format for generating solutions.\n4. Utilized a pipeline to generate text based on user input, using the trained model and tokenizer.\n5. Processed output to extract answers, handling cases where the answer was not in the expected format.\n\nNote: The provided code is part of a Machine Learning solution for an AI Mathematical Olympiad prize challenge, which requires generating solutions to mathematical problems based on given prompts."}, {"font": {"color": "white"}, "group": 0, "id": "transformers", "label": "transformers", "shape": "dot", "size": 7}, {"font": {"color": "white"}, "group": 0, "id": "pandas", "label": "pandas", "shape": "dot", "size": 9}, {"font": {"color": "white"}, "group": 0, "id": "tqdm", "label": "tqdm", "shape": "dot", "size": 5}, {"font": {"color": "white"}, "group": 0, "id": "gc", "label": "gc", "shape": "dot", "size": 7}, {"font": {"color": "white"}, "group": 0, "id": "re", "label": "re", "shape": "dot", "size": 7}, {"font": {"color": "white"}, "group": 0, "id": "sys", "label": "sys", "shape": "dot", "size": 5}, {"font": {"color": "white"}, "group": 0, "id": "subprocess", "label": "subprocess", "shape": "dot", "size": 5}, {"font": {"color": "white"}, "group": 1, "id": "collections", "label": "collections", "shape": "dot", "size": 6}, {"font": {"color": "white"}, "group": 2, "id": "numpy", "label": "numpy", "shape": "dot", "size": 7}, {"font": {"color": "white"}, "group": 3, "id": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "label": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "shape": "dot", "size": 39, "title": "Here\u0027s a summary of the unique aspects of the Machine Learning code written in Python:\n\n**InferenceHandler Class**\n\nThe `InferenceHandler` class is responsible for performing inference on a given problem and returning the predicted answer. It takes several parameters, including:\n\n* `model_path`: The path to the trained model\n* `tool_instructions`: Instructions specific to the tool being used (e.g., temperature, repetition ratio)\n* `max_new_tokens`: The maximum number of new tokens allowed in the generated text\n\nThe class has two main methods: `infer` and `infer_on_dataframe`. The `infer` method takes a problem as input and returns the predicted answer. The `infer_on_dataframe` method performs inference on an entire DataFrame containing problems and saves the results to a CSV file.\n\n**Cross Validation**\n\nThe code includes a block for cross-validation, which only runs if `IS_DEBUG` is set to `True`. This block uses the `get_aimo_examples` function to generate a subset of examples (50 in this case) and then performs inference on each example using the `InferenceHandler` class.\n\n**VLLM Support**\n\nThe code includes support for VLLM (Very Large Language Model), which is used instead of the default text generation pipeline if `USE_VLLM` is set to `True`.\n\n**Error Handling**\n\nThe code includes try-except blocks to handle errors and exceptions. For example, in the cross-validation block, an exception is caught and printed if it occurs.\n\n**Data Preprocessing**\n\nThe code includes functions for preprocessing data, such as preparing problem statements and processing output results.\n\n**Aggregation of Results**\n\nThe code includes a function called `aggregate_results` that takes two lists (boxed results and code results) as input and returns the aggregated result.\n\nOverall, this code appears to be part of a larger natural language processing (NLP) pipeline for generating text based on given problems. It incorporates various machine learning techniques, including text generation and inference, and includes support for cross-validation and error handling."}, {"font": {"color": "white"}, "group": 1, "id": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "label": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "shape": "dot", "size": 8, "title": "Here\u0027s a summary of the unique aspects of this Machine Learning code written in Python:\n\n**Class Structure**: The code defines a class with several methods for working with geometric objects (lines and points) and their relationships.\n\n**Pair Generation**: The `pairs` method generates all possible pairs of lines and points, based on a dictionary of line-object associations (`self.v2e`). This is useful for creating combinations of geometric entities to analyze or transform.\n\n**Object Name Generation**: The `name` method creates a unique name for each line-point pair by combining the line\u0027s name with the point\u0027s name. This allows for efficient storage and retrieval of line-point pairs in the `v2obj` dictionary.\n\n**Dependency Handling**: The `add_cong` method adds a dependency between two pairs of points on different lines, along with a corresponding equation (`add_eq4`). This enables the code to reason about geometric constraints and relationships.\n\n**Ratios and Equalities**: The `get_all_eqs_and_why` method generates all equations (including those derived from dependencies) and their explanations. This is useful for understanding the underlying structure of the geometric relationships.\n\n**Hashing and Pairing**: The code uses a hash-based approach to group similar line-point pairs together (`h2pairs`) and identify corresponding ratios and equalities between them. This enables the detection of symmetries and patterns in the geometric data.\n\n**Why-Dictionary Generation**: The `why` method creates a dictionary explaining why two equations are equal or proportional, which is useful for understanding the underlying relationships between geometric entities.\n\nThese unique aspects demonstrate the code\u0027s ability to manipulate and analyze complex geometric data, making it suitable for tasks such as computer vision, robotics, or spatial reasoning."}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "label": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "shape": "dot", "size": 6, "title": "This is a Python script that summarizes unique aspects of Machine Learning code written in Python. The script generates text based on the input provided and uses this generated text to summarize the code.\n\nHere\u0027s a breakdown of what the script does:\n\n1. It takes in some input and generates text based on it.\n2. It then processes this generated text to identify unique aspects of the Machine Learning code, such as code snippets and variable names.\n3. The script summarizes these unique aspects by providing an overview of the code and highlighting important features.\n\nSome notable aspects of the code include:\n\n* It uses the `tokenizer` function from the Hugging Face Transformers library to preprocess the input text.\n* It employs a temperature parameter in the generation process, which controls the level of creativity in the generated text.\n* It uses a combination of beam search and sampling to generate the text.\n* It has several conditional statements that determine what output to provide based on certain conditions.\n\nThe script also includes some error handling mechanisms to ensure that it continues running even if there are any issues with the input or generation process."}, {"font": {"color": "white"}, "group": 3, "id": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "label": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "shape": "dot", "size": 40, "title": "**Unique Aspects of the Machine Learning Code:**\n\n1. **Pre-trained Model**: The code utilizes a pre-trained model (`AutoModelForCausalLM`) from the `transformers` library, which is fine-tuned for text generation tasks.\n2. **Custom Pipeline**: A custom pipeline is created using the `pipeline` function from `transformers`, which allows for flexible control over the text generation process.\n3. **Multi-Round Processing**: The code processes each input problem multiple times (`n_repetitions`) to generate multiple outputs, which are then aggregated to produce a final answer.\n4. **Error Handling**: The code includes robust error handling using `try-except` blocks to catch and handle exceptions during the processing of inputs and outputs.\n5. **Memory Management**: The code uses `torch.cuda.empty_cache()` and `gc.collect()` to manage memory usage and prevent memory leaks.\n6. **Post-processing**: The code applies post-processing techniques, such as filtering and counting, to refine the generated answers.\n7. **Submission Generation**: The final answers are used to generate a submission file (`submission.csv`) containing the predicted answers for each input problem.\n\n**Key Libraries and Modules Used:**\n\n1. `transformers`: For pre-trained models and text generation tasks.\n2. `torch`: For deep learning and memory management.\n3. `pandas`: For data manipulation and processing.\n4. `numpy`: For numerical computations and array operations.\n5. `tqdm`: For progress bar visualization.\n\n**Key Functions:**\n\n1. `naive_parse`: A custom function for parsing the generated text to extract answers.\n2. `process_output`: A custom function for processing the output of the text generation model, including error handling and post-processing.\n3. `pipeline`: The custom pipeline created using the `transformers` library.\n4. `final_answers`: A function for aggregating the processed outputs to produce final answers.\n\n**Unique Features:**\n\n1. **Multi-round processing**: The code processes each input problem multiple times to generate multiple outputs, which are then aggregated to produce a final answer.\n2. **Error handling**: The code includes robust error handling using `try-except` blocks to catch and handle exceptions during the processing of inputs and outputs.\n3. **Memory management**: The code uses `torch.cuda.empty_cache()` and `gc.collect()` to manage memory usage and prevent memory leaks.\n\nOverall, this code demonstrates a unique blend of natural language processing (NLP) and machine learning techniques to solve a complex problem in the context of an AI mathematical olympiad challenge."}, {"font": {"color": "white"}, "group": 0, "id": "time", "label": "time", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 0, "id": "math", "label": "math", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 0, "id": "random", "label": "random", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 2, "id": "os", "label": "os", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "keras", "label": "keras", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 2, "id": "keras_nlp", "label": "keras_nlp", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "plotly", "label": "plotly", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "IPython", "label": "IPython", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "vllm", "label": "vllm", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "aimo", "label": "aimo", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "sympy", "label": "sympy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "typing", "label": "typing", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "kaggle_datasets", "label": "kaggle_datasets", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "dataclasses", "label": "dataclasses", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "datetime", "label": "datetime", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "zipfile", "label": "zipfile", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "glob", "label": "glob", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "warnings", "label": "warnings", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "requests", "label": "requests", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "textwrap", "label": "textwrap", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "hashlib", "label": "hashlib", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "imageio", "label": "imageio", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "urllib", "label": "urllib", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "pickle", "label": "pickle", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "shutil", "label": "shutil", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "string", "label": "string", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "json", "label": "json", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "copy", "label": "copy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "gzip", "label": "gzip", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "ast", "label": "ast", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "io", "label": "io", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "seaborn", "label": "seaborn", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 3, "id": "PIL", "label": "PIL", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "re,", "label": "re,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "torch,", "label": "torch,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "accelerate", "label": "accelerate", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "signal,", "label": "signal,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "sklearn", "label": "sklearn", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "matplotlib", "label": "matplotlib", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "tensorflow", "label": "tensorflow", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "Levenshtein", "label": "Levenshtein", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "tifffile", "label": "tifffile", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "cv2", "label": "cv2", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "__future__", "label": "__future__", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 3, "id": "types", "label": "types", "shape": "dot", "size": 1}]);
                  edges = new vis.DataSet([{"from": "torch", "to": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "transformers", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "pandas", "value": 9.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "tqdm", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "gc", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "re", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "sys", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "subprocess", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "collections", "value": 6.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "numpy", "value": 10.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "time", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "math", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "random", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "os", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras_nlp", "value": 1.0, "width": 1}, {"from": "os", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "os", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "plotly", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "IPython", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "vllm", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "aimo", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "sympy", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "typing", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "kaggle_datasets", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "dataclasses", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "datetime", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "zipfile", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "glob", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "warnings", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "requests", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "textwrap", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "hashlib", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "imageio", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "urllib", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "pickle", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "shutil", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "string", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "json", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "copy", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "gzip", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "ast", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "io", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "seaborn", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "PIL", "value": 2.0, "width": 1}, {"from": "plotly", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "IPython", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "aimo", "to": "\u2714\ufe0f ID_8 --- Updated Code Interpretation \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "typing", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "kaggle_datasets", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "datetime", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "zipfile", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "glob", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "warnings", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "requests", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "hashlib", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "imageio", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "urllib", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "pickle", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "shutil", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "string", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "json", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "gzip", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "ast", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "io", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "seaborn", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "PIL", "to": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "to": "re,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "to": "torch,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "to": "accelerate", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_6 --- Deepseek Math \u2714\ufe0f", "to": "signal,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "sklearn", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "matplotlib", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "tensorflow", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "Levenshtein", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "tifffile", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "cv2", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "__future__", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "types", "value": 1.0, "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": "physics"
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>