<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 1920px;
                 height: 1080px;
                 background-color: #222222;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             
             #config {
                 float: left;
                 width: 400px;
                 height: 600px;
             }
             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        
            <div id="config"></div>
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"font": {"color": "white"}, "group": 0, "id": "torch", "label": "torch", "shape": "dot", "size": 6}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "label": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "shape": "dot", "size": 10, "title": "Here\u0027s a summary of the unique aspects of this Machine Learning code written in Python:\n\n1. **Text Generation**: The code uses a text generation model to generate text based on input prompts. It takes into account previous generated output (past key) and uses it as context for future generations.\n\n2. **Evaluation**: The generated text is evaluated using two metrics: \"code\" output, which is the output of running Python code, and \"result\" output, which is the result of processing the generated text. The best answer is tracked based on the frequency of correct answers.\n\n3. **Private Mode**: The code has a private mode where it processes additional data (df) and compares its predictions with actual answers. It also calculates the match rate between predicted and actual answers.\n\n4. **Submission**: The code generates a submission file \"submission.csv\" containing the best answer for each question, along with other statistics.\n\n5. **Code Execution**: The code executes Python code (code.py) using the `subprocess` module and prints the output to the console.\n\nUnique aspects of this code include:\n\n- Integration of text generation and evaluation metrics\n- Use of previous generated output as context for future generations\n- Private mode processing and comparison with actual answers\n- Submission file generation and statistics tracking\n- Execution of Python code using `subprocess` module"}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "label": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "shape": "dot", "size": 13, "title": "The unique aspects of this Machine Learning code written in Python are:\n\n1. **Text Generation**: The code uses a transformer-based language model to generate text based on a given prompt.\n\n2. **Code Evaluation**: It also evaluates the generated code using `eval()` and checks if it matches the expected output.\n\n3. **Counter-Based Analysis**: The code counts the occurrences of different outputs and identifies the most common ones, which could be useful for analyzing patterns in the data.\n\n4. **Conditional Statements**: It uses conditional statements (e.g., `if`, `elif`, `else`) to control the flow of the program based on certain conditions.\n\n5. **Error Handling**: The code includes try-except blocks to handle exceptions and errors that might occur during execution.\n\n6. **Subprocess Execution**: It uses the subprocess module to execute a shell command, specifically to run the generated code in an isolated environment.\n\n7. **Statistics and Data Analysis**: The code calculates statistics (e.g., mean, count) and analyzes data using pandas, which is useful for summarizing and visualizing large datasets.\n\n8. **Private Mode**: It has a `PRIVATE` flag that enables additional features, such as converting output arrays to lists and calculating the match between predicted and actual answers.\n\nThese unique aspects demonstrate the code\u0027s ability to perform complex tasks, including text generation, code evaluation, data analysis, and error handling, which are essential skills for a Machine Learning model."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "label": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "shape": "dot", "size": 5, "title": "Unique aspects:\n1. The use of the Mixtral8x7b model for causal language generation.\n2. The integration of BitsAndBytesConfig to enable quantization and compute dtype.\n3. The application of gradient checkpointing to prevent GPU memory overflow.\n\nSteps taken:\n1. Import necessary libraries, including PyTorch, Transformers, Pandas, and TQDM.\n2. Load the pre-trained Mixtral8x7b model and tokenizer.\n3. Define a custom function to generate prompts for the model based on mathematical problems.\n4. Process the output of the model\u0027s generation pipeline to extract code blocks and execute them to obtain results.\n5. Integrate natural language reasoning with programs to solve mathematical problems.\n6. Use self-consistency and generated code reasoning evaluation to improve arithmetic hallucinations.\n\nSummary:\nThis code uses the Mixtral8x7b model for causal language generation, integrating it with BitsAndBytesConfig for quantization and compute dtype. The code also employs gradient checkpointing to prevent GPU memory overflow."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "label": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "shape": "dot", "size": 6, "title": "A Machine Learning code written in Python!\n\nHere are the unique aspects of this code:\n\n**1. Pretrained Model**: The code uses a pre-trained model `AutoModelForCausalLM` from the Hugging Face Transformers library, which is specifically designed for causal language modeling tasks.\n\n**2. Custom Pipeline**: A custom pipeline is created using the `pipeline` function from Transformers, which takes in the pre-trained model and tokenizer as inputs. This pipeline is used to generate text based on a given input prompt.\n\n**3. Natural Language Reasoning**: The code integrates natural language reasoning with programming to solve mathematical problems. It uses the generated text output from the pipeline to parse and evaluate mathematical expressions.\n\n**4. Error Handling**: The code includes robust error handling using `try`-`except` blocks to handle exceptions and errors that may occur during the execution of the code.\n\n**5. Caching and Memory Management**: The code uses `torch.cuda.empty_cache()` to empty the GPU cache and `gc.collect()` to collect garbage, which helps manage memory efficiently.\n\n**6. Repetition and Averaging**: The code runs multiple iterations (repetitions) for each problem to generate multiple outputs, and then averages or selects the best output based on certain criteria (e.g., most common answer).\n\n**7. Submission Generation**: The final answers are stored in a Pandas dataframe and exported as a CSV file (`submission.csv`) for submission.\n\n**8. Private vs Public Mode**: The code has a private mode (`PRIVATE = True`) that uses different settings and data sources compared to the public mode (`PRIVATE = False`).\n\nThese unique aspects demonstrate the complexity and creativity of this Machine Learning code!"}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "label": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "shape": "dot", "size": 14, "title": "Unique aspects:\n1. The use of a custom pipeline for text generation using the transformers library, which enables integration with programs to solve mathematical problems.\n2. The employment of self-consistency and generated code reasoning evaluation to improve arithmetic hallucinations.\n\nSteps taken:\n1. Import necessary libraries, including numpy, pandas, and transformers.\n2. Define a function `process_output` to process the generated text output from the pipeline.\n3. Create a custom prompt for each problem using the tokenizer\u0027s `apply_chat_template` method.\n4. Use the pipeline to generate responses for each problem, with parameters such as max new tokens, do sample, temperature, and return full text.\n5. Process the generated responses using the `process_output` function.\n6. Calculate the final answers by applying a ranking algorithm to the processed outputs.\n\nNote: The code appears to be a solution to a Kaggle competition, \"AI Mathematical Olympiad Prize\", which involved solving math problems using natural language processing and machine learning techniques."}, {"font": {"color": "white"}, "group": 0, "id": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "label": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "shape": "dot", "size": 10, "title": "Here\u0027s a summary of the unique aspects of this Machine Learning code written in Python:\n\n**Unique Aspects:**\n\n1. **Custom Pair Generation**: The `pairs` method generates pairs of tuples representing line and point names, which are used to create equations for geometric constraints.\n\n2. **Hashing and Clustering**: The code uses a custom hashing function (`hashed`) and clustering algorithm (not explicitly shown) to group similar equation pairs together, allowing for efficient processing and merging of equivalent equations.\n\n3. **Equation Merging**: The `merged` dictionary is used to merge equivalent equations, reducing the number of unique equations and improving computational efficiency.\n\n4. **Customized Equation Generation**: The code generates custom equations based on the input geometric constraints using the `add_cong` method.\n\n5. **Ratios Calculation**: The code calculates ratios between pairs of lines and points, taking into account numerical values and dependencies between them.\n\n6. **Why-Explanation Generation**: The `why_dict` dictionary is used to generate explanations for why certain equations are true, based on the input geometric constraints and dependencies.\n\n7. **Custom Data Structures**: The code uses custom data structures such as `defaultdict`, `Generator`, and `list[gm.Point]` to efficiently store and process geometric data.\n\n8. **Geometric Operations**: The code performs various geometric operations such as line and point manipulation, equation generation, and ratio calculation using Python\u0027s built-in arithmetic operators and methods.\n\n**Overall Insights:**\n\nThis code appears to be part of a larger program that deals with solving geometric constraints in computer graphics or computational geometry. The unique aspects mentioned above indicate a focus on efficiency, scalability, and customization for specific problem domains."}, {"font": {"color": "white"}, "group": 0, "id": "transformers", "label": "transformers", "shape": "dot", "size": 8}, {"font": {"color": "white"}, "group": 0, "id": "pandas", "label": "pandas", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "group": 0, "id": "tqdm", "label": "tqdm", "shape": "dot", "size": 6}, {"font": {"color": "white"}, "group": 0, "id": "gc", "label": "gc", "shape": "dot", "size": 8}, {"font": {"color": "white"}, "group": 0, "id": "re", "label": "re", "shape": "dot", "size": 8}, {"font": {"color": "white"}, "group": 0, "id": "sys", "label": "sys", "shape": "dot", "size": 6}, {"font": {"color": "white"}, "group": 0, "id": "subprocess", "label": "subprocess", "shape": "dot", "size": 6}, {"font": {"color": "white"}, "group": 2, "id": "collections", "label": "collections", "shape": "dot", "size": 7}, {"font": {"color": "white"}, "group": 2, "id": "numpy", "label": "numpy", "shape": "dot", "size": 8}, {"font": {"color": "white"}, "group": 1, "id": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "label": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "shape": "dot", "size": 39, "title": "Unique aspects:\n1. The use of OpenMath models, specifically OpenMath- Mistral-7B-v0.1, for solving mathematical problems.\n2. The integration of BitsAndBytesConfig for quantization and compute dtype.\n\nSteps taken:\n1. Import necessary libraries, including torch, transformers, and pandas.\n2. Load the pre-trained OpenMath-Mistral-7B-v0.1 model and tokenizer.\n3. Define a prompt template for generating solutions to mathematical problems.\n4. Iterate through a dataset of math problems and generate solutions using the pipeline.\n5. Parse generated text to extract answers and append them to the answers list.\n6. Save the answers to a submission.csv file.\n\nNote: The code appears to be solving a specific mathematical olympiad problem, so it\u0027s not general-purpose machine learning code."}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "label": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "shape": "dot", "size": 8, "title": "You\u0027re fine-tuning a Machine Learning model using Low-Rank Adaptation (LoRA) in Python!\n\n**What is LoRA?**\nLoRA is a method to fine-tune large language models (LLMs) efficiently. It involves freezing the weights of the LLM and injecting trainable rank-decomposition matrices.\n\nIn an LLM, you have a pre-trained dense layer represented by a $d \\times d$ weight matrix, denoted as $W_0$. You initialize two additional dense layers, labeled as $A$ and $B$, with shapes $d \\times r$ and $r \\times d$, respectively. Here, $r$ denotes the rank, which is typically much smaller than $d$.\n\nThe model\u0027s output was computed using the equation `output = W_0 * x + b`, where `x` is the input and `b` is the bias term. LoRA modifies this equation by introducing two new matrices, $A$ and $B$, as follows:\n\n`output = (W_0 @ A) @ B + b`\n\nHere, `@` denotes matrix multiplication.\n\nThe key idea behind LoRA is to reduce the dimensionality of the input data while preserving its essential features. This is achieved by multiplying the input with a low-rank matrix $A$ and then projecting it onto a lower-dimensional space using a second low-rank matrix $B$. By doing so, you can significantly reduce the number of model parameters while maintaining performance.\n\n**Inference on AIMO Data**\nYou\u0027ve inferred your model on the AIMO (competition) dataset. You used the `infer` function to generate predictions for each problem in the test set and stored them in a DataFrame called `test_pred_ df`.\n\nYou also prepared a submission file by converting the prediction DataFrame into a CSV file named \"submission.csv\" using the `to_csv` method.\n\n**Tips for Improvement**\nTo enhance performance, you can try:\n\n1.  Train on the full data instead of first 1000 samples.\n2.  Use the non-instruction-tuned version of Gemma.\n3.  Increase the `sequence_length`.\n4.  Experiment with advanced prompt engineering techniques.\n5.  Implement augmentation to increase the number of samples.\n6.  Utilize a learning rate scheduler.\n\n**References**\nYou\u0027ve referenced some useful resources for further reading:\n\n1. [Fine-tune Gemma models in Keras using LoRA](https://www.kaggle.com/code/nilaychauhan/fine-tune-gemma-models-in-keras-using-lora)\n2. [Parameter-efficient fine-tuning of GPT-2 with LoRA](https://keras.io/examples/nlp/parameter_efficient_finetuning_of_gpt2_with_lora/)\n3. [Gemma - KerasNLP](https://keras.io/api/keras_nlp/models/gemma/)"}, {"font": {"color": "white"}, "group": 2, "id": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "label": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "shape": "dot", "size": 6, "title": "Here is a summary of the unique aspects of this Machine Learning code written in Python:\n\n1. **Pre-trained Model**: The code uses a pre-trained AutoModelForCausalLM model, which is a type of transformer-based language model.\n2. **Text Generation Pipeline**: A pipeline is created using the `transformers` library to generate text based on input prompts.\n3. **Natural Language Reasoning**: The code integrates natural language reasoning with programming to solve mathematical problems.\n4. **Repetitive Processing**: The code processes output from the text generation pipeline multiple times (8 times by default) and keeps track of results and answers.\n5. **Error Handling**: The code has robust error handling, including catching exceptions and printing error messages.\n6. **Dataframe Manipulation**: The code uses Pandas dataframes to read in input data, process output, and write out results.\n7. **Subprocess Execution**: The code executes shell commands using the `subprocess` library to run Python scripts and timeout after 7 seconds.\n8. **CUDA Support**: The code enables CUDA support for faster processing on NVIDIA GPUs.\n\nSome notable libraries used in this code include:\n\n* `transformers`: A popular library for natural language processing tasks, such as text generation and language modeling.\n* `torch`: A Python package for building and training neural networks.\n* `pandas`: A library for data manipulation and analysis.\n* `tqdm`: A library for creating progress bars in Python.\n\nOverall, this code demonstrates a unique combination of natural language processing, machine learning, and programming to solve mathematical problems."}, {"font": {"color": "white"}, "group": 1, "id": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "label": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "shape": "dot", "size": 40, "title": "I\u0027m an AI assistant, and my purpose is to summarize unique aspects of Machine Learning code written in Python.\n\nThe provided code appears to be a part of a larger project focused on generating code based on problem statements using the VLLM (Vitality Language Model) or another text generation pipeline. Here are some interesting features:\n\n1. **InferenceHandler**: This class is responsible for running inference on given problems and storing results in a DataFrame. It takes various parameters, such as model path, tool instructions, temperature, number of repetitions, etc.\n\n2. **Code Generation**: The code uses the VLLM or another text generation pipeline to generate code based on problem statements. This process involves running multiple iterations (repetitions) with adjustable temperatures and maximum new tokens allowed.\n\n3. **Aggregation**: The generated outputs are then aggregated into final results using the `aggregate_results` function, which takes boxed and code results as input.\n\n4. **Cross Validation**: A subset of examples from the main dataset is used for cross-validation (CV). This is done within a block that only runs if debugging mode is enabled.\n\n5. **Error Handling**: The code includes error handling mechanisms using `try-except` blocks to handle potential errors during execution, such as file removal and processing output.\n\nThese are some of the unique aspects of this Machine Learning code written in Python. If you have any specific questions or would like me to clarify certain parts, feel free to ask!"}, {"font": {"color": "white"}, "group": 0, "id": "time", "label": "time", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 0, "id": "math", "label": "math", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 0, "id": "random", "label": "random", "shape": "dot", "size": 4}, {"font": {"color": "white"}, "group": 2, "id": "os", "label": "os", "shape": "dot", "size": 3}, {"font": {"color": "white"}, "group": 2, "id": "keras", "label": "keras", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 2, "id": "keras_nlp", "label": "keras_nlp", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "plotly", "label": "plotly", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "IPython", "label": "IPython", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "vllm", "label": "vllm", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 0, "id": "aimo", "label": "aimo", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "sympy", "label": "sympy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "typing", "label": "typing", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "kaggle_datasets", "label": "kaggle_datasets", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "dataclasses", "label": "dataclasses", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "datetime", "label": "datetime", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "zipfile", "label": "zipfile", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "glob", "label": "glob", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "warnings", "label": "warnings", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "requests", "label": "requests", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "textwrap", "label": "textwrap", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "hashlib", "label": "hashlib", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "imageio", "label": "imageio", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "urllib", "label": "urllib", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "pickle", "label": "pickle", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "shutil", "label": "shutil", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "string", "label": "string", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "json", "label": "json", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "copy", "label": "copy", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "gzip", "label": "gzip", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "ast", "label": "ast", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "io", "label": "io", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "seaborn", "label": "seaborn", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 1, "id": "PIL", "label": "PIL", "shape": "dot", "size": 2}, {"font": {"color": "white"}, "group": 2, "id": "re,", "label": "re,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 2, "id": "torch,", "label": "torch,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 2, "id": "accelerate", "label": "accelerate", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 2, "id": "signal,", "label": "signal,", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "sklearn", "label": "sklearn", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "matplotlib", "label": "matplotlib", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "tensorflow", "label": "tensorflow", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "Levenshtein", "label": "Levenshtein", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "tifffile", "label": "tifffile", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "cv2", "label": "cv2", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "__future__", "label": "__future__", "shape": "dot", "size": 1}, {"font": {"color": "white"}, "group": 1, "id": "types", "label": "types", "shape": "dot", "size": 1}]);
                  edges = new vis.DataSet([{"from": "torch", "to": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "torch", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "transformers", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "pandas", "value": 10.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "tqdm", "value": 9.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "gc", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "re", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "sys", "value": 6.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "subprocess", "value": 6.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "collections", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_0 --- AIMO Zero-Shot SC MMOS-DeepSeekMath \u2714\ufe0f", "to": "numpy", "value": 11.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "transformers", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "pandas", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 10.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "tqdm", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 9.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_2 --- AIMO Mixtral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "gc", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_5 --- AIMO OpenMath-Mistral Baseline \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "re", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "sys", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "subprocess", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 6.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "collections", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 7.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "numpy", "to": "\u2714\ufe0f ID_9 --- Pure RNG \u2714\ufe0f", "value": 11.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "time", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "math", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_1 --- Improved Code Interpretation \u2714\ufe0f", "to": "random", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "time", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "math", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "random", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 4.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "os", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_3 --- AIMO: KerasNLP Starter \u2714\ufe0f", "to": "keras_nlp", "value": 1.0, "width": 1}, {"from": "os", "to": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "os", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "plotly", "value": 8.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "IPython", "value": 5.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "vllm", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "aimo", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "sympy", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "typing", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "kaggle_datasets", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "dataclasses", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "datetime", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "zipfile", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "glob", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "warnings", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "requests", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "textwrap", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "hashlib", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "imageio", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "urllib", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "pickle", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "shutil", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "string", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "json", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "copy", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "gzip", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "ast", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "io", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "seaborn", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_4 --- AIMO - Let\u0027s Learn Together \u2714\ufe0f", "to": "PIL", "value": 2.0, "width": 1}, {"from": "plotly", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 8.0, "width": 1}, {"from": "IPython", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 5.0, "width": 1}, {"from": "aimo", "to": "\u2714\ufe0f ID_6 --- Updated Code Interpretation \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "typing", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "kaggle_datasets", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "datetime", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "zipfile", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "glob", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "warnings", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "requests", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "hashlib", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "imageio", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "urllib", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "pickle", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "shutil", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "string", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "json", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "gzip", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "ast", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "io", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "seaborn", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "PIL", "to": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "value": 2.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "to": "re,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "to": "torch,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "to": "accelerate", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_7 --- Deepseek Math \u2714\ufe0f", "to": "signal,", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "sklearn", "value": 3.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "matplotlib", "value": 7.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "tensorflow", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "Levenshtein", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "tifffile", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "cv2", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "__future__", "value": 1.0, "width": 1}, {"from": "\u2714\ufe0f ID_8 --- Let\u0027s Learn Together - DeepMind\u0027s AlphaGeometry \u2714\ufe0f", "to": "types", "value": 1.0, "width": 1}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {
    "configure": {
        "enabled": true,
        "filter": "physics"
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": true,
            "type": "dynamic"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};

                  


                  
                  // if this network requires displaying the configure window,
                  // put it in its div
                  options.configure["container"] = document.getElementById("config");
                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>